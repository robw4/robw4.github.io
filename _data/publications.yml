- title: "There and Back Again: Learning to Simulate Radar Data for Real-World Applications"
  youtube: C3N0R-Jlu7I
  authors: '<i>Rob Weston</i>, Oiwi Parker Jones and Ingmar Posner.'
  conference: "In 2021 International Conference on Robotics and Automation (ICRA)"
  paper: https://arxiv.org/pdf/2011.14389.pdf
  poster:
  id: "tab"
  abstract:  Simulating  realistic  radar  data  has  the  potential  to  significantly  accelerate  the  development  of  data-driven approaches  to  radar  processing.  However,  it  is  fraught  with difficulty   due   to   the   notoriously   complex   image   formation process.   Here   we   propose   to   learn   a   radar   sensor   model capable  of  synthesising  faithful  radar  observations  based  on simulated elevation maps. In particular, we adopt an adversarial approach  to  learning  a forward sensor  model  from  unaligned radar  examples.  In  addition,  modelling  the backward model encourages  the  output  to  remain  aligned  to  the  world  state through  a  cyclical  consistency  criterion.  The  backward  model is further constrained to predict elevation maps from real radar data that are grounded by partial measurements obtained from corresponding  lidar  scans.  Both  models  are  trained  in  a  joint optimisation.  We  demonstrate  the  efficacy  of  our  approach  by evaluating  a  down-stream  segmentation  model  trained  purely on  simulated  data  in  a  real-world  deployment.  This  achieves performance  within  four  percentage  points  of  the  same  model trained  entirely  on  real  data.
  post: /2021/05/27/there-and-back-again.html
  presentation: xVL4xUMlDY0
- title: "Masking By Moving: Learning Distraction-Free Radar Odometry from Pose Information"
  youtube: "eG4Q-j3_6dk"
  authors: 'Dan Barnes, <i>Rob Weston</i>, and Ingmar Posner.'
  conference: "In 2020 Conference on Robot Learning (CoRL)"
  paper: "https://arxiv.org/pdf/1909.03752.pdf"
  poster: "https://dbarnes.github.io/assets/projects/masking-by-moving/MaskingByMovingCoRLPosterCompressedGithub.pdf"
  id: "mbym"
  abstract: This paper presents an end-to-end radar odometry system which delivers robust, real-time pose estimates based on a learned embedding space free of
    sensing artefacts and distractor objects. The system deploys a fully differentiable,
    correlation-based radar matching approach. This provides the same level of interpretability as established scan-matching methods and allows for a principled
    derivation of uncertainty estimates. The system is trained in a (self-)supervised
    way using only previously obtained pose information as a training signal. Using
    280km of urban driving data, we demonstrate that our approach outperforms the
    previous state-of-the-art in radar odometry by reducing errors by up 68% whilst
    running an order of magnitude faster.
- title: "Probably Unknown: Deep Inverse Sensor Modelling In Radar"
  youtube: "zIleQXrFOGM"
  authors: '<i>Rob Weston</i>, Sarah Cen, Paul Newman, and Ingmar Posner.'
  conference: "In 2019 International Conference on Robotics and Automation (ICRA), pp. 5446-5452. IEEE, 2019"
  paper: "https://arxiv.org/abs/1810.08151"
  poster: "/assets/pdf/deep-ism-icra-poster.pdf"
  id: "probs"
  abstract: Radar presents a promising alternative to lidar
    and vision in autonomous vehicle applications, able to detect
    objects at long range under a variety of weather conditions.
    However, distinguishing between occupied and free space from
    raw radar power returns is challenging due to complex interactions between sensor noise and occlusion.
    To counter this we propose to learn an Inverse Sensor Model
    (ISM) converting a raw radar scan to a grid map of occupancy
    probabilities using a deep neural network. Our network is selfsupervised using partial occupancy labels generated by lidar,
    allowing a robot to learn about world occupancy from past experience without human supervision. We evaluate our approach
    on five hours of data recorded in a dynamic urban environment.
    By accounting for the scene context of each grid cell our model
    is able to successfully segment the world into occupied and
    free space, outperforming standard CFAR filtering approaches.
    Additionally by incorporating heteroscedastic uncertainty into
    our model formulation, we are able to quantify the variance
    in the uncertainty throughout the sensor observation. Through
    this mechanism we are able to successfully identify regions of
    space that are likely to be occluded.

